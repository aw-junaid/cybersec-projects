#!/usr/bin/env python3
"""
Basic Malware Analysis Sandbox - Python Implementation
Safe execution environment for malware analysis
"""

import os
import sys
import time
import json
import psutil
import socket
import threading
import subprocess
import tempfile
import hashlib
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import argparse

class MalwareSandbox:
    """Malware analysis sandbox with monitoring capabilities"""
    
    def __init__(self, sample_path: str, timeout: int = 60):
        self.sample_path = sample_path
        self.timeout = timeout
        self.analysis_id = hashlib.md5(f"{sample_path}{datetime.now()}".encode()).hexdigest()[:8]
        self.temp_dir = tempfile.mkdtemp(prefix=f"malware_analysis_{self.analysis_id}_")
        self.monitoring_active = False
        self.analysis_results = {}
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(self.temp_dir, 'sandbox.log')),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def analyze_sample(self) -> Dict[str, Any]:
        """Main analysis routine"""
        self.logger.info(f"Starting analysis of: {self.sample_path}")
        self.logger.info(f"Analysis ID: {self.analysis_id}")
        self.logger.info(f"Temp directory: {self.temp_dir}")
        
        try:
            # Pre-execution analysis
            self.analysis_results['pre_analysis'] = self.pre_execution_analysis()
            
            # Start monitoring
            self.start_monitoring()
            
            # Execute sample
            self.analysis_results['execution'] = self.execute_sample()
            
            # Stop monitoring and collect results
            self.stop_monitoring()
            self.analysis_results['post_analysis'] = self.post_execution_analysis()
            
            # Generate report
            report = self.generate_report()
            
            self.logger.info("Analysis completed successfully")
            return report
            
        except Exception as e:
            self.logger.error(f"Analysis failed: {e}")
            self.stop_monitoring()
            raise
    
    def pre_execution_analysis(self) -> Dict[str, Any]:
        """Analyze sample before execution"""
        self.logger.info("Performing pre-execution analysis")
        
        file_info = {
            'filename': os.path.basename(self.sample_path),
            'file_size': os.path.getsize(self.sample_path),
            'file_type': self.get_file_type(),
            'md5': self.calculate_hash('md5'),
            'sha1': self.calculate_hash('sha1'),
            'sha256': self.calculate_hash('sha256'),
            'entropy': self.calculate_entropy(),
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        # Basic static analysis
        strings = self.extract_strings()
        file_info['suspicious_strings'] = self.analyze_strings(strings)
        
        return file_info
    
    def get_file_type(self) -> str:
        """Determine file type"""
        try:
            import magic
            return magic.from_file(self.sample_path)
        except:
            # Fallback to file command
            result = subprocess.run(['file', self.sample_path], capture_output=True, text=True)
            return result.stdout.strip()
    
    def calculate_hash(self, algorithm: str) -> str:
        """Calculate file hash"""
        hash_obj = hashlib.new(algorithm)
        with open(self.sample_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_obj.update(chunk)
        return hash_obj.hexdigest()
    
    def calculate_entropy(self) -> float:
        """Calculate file entropy"""
        try:
            with open(self.sample_path, 'rb') as f:
                data = f.read()
            
            if not data:
                return 0.0
                
            entropy = 0.0
            for x in range(256):
                p_x = float(data.count(x)) / len(data)
                if p_x > 0:
                    entropy += - p_x * (p_x.bit_length() - 1)
            return entropy
        except:
            return 0.0
    
    def extract_strings(self, min_length: int = 4) -> List[str]:
        """Extract ASCII strings from binary"""
        strings = []
        try:
            with open(self.sample_path, 'rb') as f:
                current_string = b''
                for byte in iter(lambda: f.read(1), b''):
                    if 32 <= byte[0] <= 126:  # Printable ASCII
                        current_string += byte
                    else:
                        if len(current_string) >= min_length:
                            strings.append(current_string.decode('ascii', errors='ignore'))
                        current_string = b''
        except Exception as e:
            self.logger.error(f"String extraction failed: {e}")
        
        return strings
    
    def analyze_strings(self, strings: List[str]) -> Dict[str, Any]:
        """Analyze extracted strings for suspicious patterns"""
        suspicious_patterns = {
            'urls': [],
            'ips': [],
            'domains': [],
            'registry_keys': [],
            'file_paths': [],
            'suspicious_keywords': []
        }
        
        import re
        
        for string in strings:
            # URLs
            url_pattern = r'https?://[^\s]+'
            if re.match(url_pattern, string):
                suspicious_patterns['urls'].append(string)
            
            # IP addresses
            ip_pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'
            if re.match(ip_pattern, string):
                suspicious_patterns['ips'].append(string)
            
            # Domains
            domain_pattern = r'\b[a-zA-Z0-9]+([\-\.]{1}[a-zA-Z0-9]+)*\.[a-zA-Z]{2,}\b'
            if re.match(domain_pattern, string) and 'http' not in string:
                suspicious_patterns['domains'].append(string)
            
            # Registry keys
            if string.startswith('HKEY_') or '\\Software\\' in string:
                suspicious_patterns['registry_keys'].append(string)
            
            # File paths
            if 'C:\\' in string or '/bin/' in string or '/tmp/' in string:
                suspicious_patterns['file_paths'].append(string)
            
            # Suspicious keywords
            suspicious_keywords = ['malware', 'virus', 'trojan', 'backdoor', 'keylogger', 
                                 'ransomware', 'botnet', 'exploit', 'payload', 'inject']
            if any(keyword in string.lower() for keyword in suspicious_keywords):
                suspicious_patterns['suspicious_keywords'].append(string)
        
        return suspicious_patterns
    
    def start_monitoring(self):
        """Start system monitoring"""
        self.logger.info("Starting system monitoring")
        self.monitoring_active = True
        
        # Initialize monitoring data
        self.monitoring_data = {
            'processes': [],
            'network_connections': [],
            'file_operations': [],
            'registry_changes': [],
            'system_calls': []
        }
        
        # Start monitoring threads
        self.process_monitor_thread = threading.Thread(target=self.monitor_processes)
        self.network_monitor_thread = threading.Thread(target=self.monitor_network)
        self.file_monitor_thread = threading.Thread(target=self.monitor_file_operations)
        
        self.process_monitor_thread.daemon = True
        self.network_monitor_thread.daemon = True
        self.file_monitor_thread.daemon = True
        
        self.process_monitor_thread.start()
        self.network_monitor_thread.start()
        self.file_monitor_thread.start()
    
    def stop_monitoring(self):
        """Stop system monitoring"""
        self.logger.info("Stopping system monitoring")
        self.monitoring_active = False
        
        # Wait for threads to finish
        if hasattr(self, 'process_monitor_thread'):
            self.process_monitor_thread.join(timeout=5)
        if hasattr(self, 'network_monitor_thread'):
            self.network_monitor_thread.join(timeout=5)
        if hasattr(self, 'file_monitor_thread'):
            self.file_monitor_thread.join(timeout=5)
    
    def monitor_processes(self):
        """Monitor process creation and termination"""
        initial_processes = set(p.pid for p in psutil.process_iter())
        
        while self.monitoring_active:
            try:
                current_processes = set(p.pid for p in psutil.process_iter())
                new_processes = current_processes - initial_processes
                
                for pid in new_processes:
                    try:
                        process = psutil.Process(pid)
                        process_info = {
                            'pid': pid,
                            'name': process.name(),
                            'cmdline': process.cmdline(),
                            'create_time': process.create_time(),
                            'parent_pid': process.ppid(),
                            'username': process.username(),
                            'timestamp': datetime.now().isoformat()
                        }
                        self.monitoring_data['processes'].append(process_info)
                        self.logger.info(f"New process: {process.name()} (PID: {pid})")
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
                
                initial_processes = current_processes
                time.sleep(1)
                
            except Exception as e:
                self.logger.error(f"Process monitoring error: {e}")
                time.sleep(5)
    
    def monitor_network(self):
        """Monitor network connections"""
        initial_connections = set()
        
        while self.monitoring_active:
            try:
                connections = psutil.net_connections()
                for conn in connections:
                    conn_id = f"{conn.laddr}_{conn.raddr}_{conn.pid}_{conn.status}"
                    
                    if conn_id not in initial_connections:
                        conn_info = {
                            'pid': conn.pid,
                            'family': conn.family.name,
                            'type': conn.type.name,
                            'local_address': str(conn.laddr) if conn.laddr else None,
                            'remote_address': str(conn.raddr) if conn.raddr else None,
                            'status': conn.status,
                            'timestamp': datetime.now().isoformat()
                        }
                        self.monitoring_data['network_connections'].append(conn_info)
                        self.logger.info(f"New connection: {conn_info}")
                        initial_connections.add(conn_id)
                
                time.sleep(2)
                
            except Exception as e:
                self.logger.error(f"Network monitoring error: {e}")
                time.sleep(5)
    
    def monitor_file_operations(self):
        """Monitor file system operations (simulated)"""
        # In a real implementation, this would use tools like inotify or watchdog
        while self.monitoring_active:
            try:
                # Simulate file operation detection
                time.sleep(3)
            except Exception as e:
                self.logger.error(f"File monitoring error: {e}")
                time.sleep(5)
    
    def execute_sample(self) -> Dict[str, Any]:
        """Execute the malware sample in controlled environment"""
        self.logger.info(f"Executing sample: {self.sample_path}")
        
        execution_info = {
            'start_time': datetime.now().isoformat(),
            'command': '',
            'return_code': None,
            'stdout': '',
            'stderr': '',
            'duration': 0
        }
        
        try:
            start_time = time.time()
            
            # Determine execution method based on file type
            if self.sample_path.endswith('.py'):
                cmd = ['python3', self.sample_path]
            elif self.sample_path.endswith('.exe'):
                # On Windows, would use subprocess directly
                # On Linux, might use wine or other compatibility layer
                cmd = ['echo', 'Windows executable - execution simulated']
            else:
                cmd = ['chmod', '+x', self.sample_path, '&&', './' + self.sample_path]
            
            execution_info['command'] = ' '.join(cmd)
            
            # Execute with timeout
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=self.temp_dir
            )
            
            try:
                stdout, stderr = process.communicate(timeout=self.timeout)
                execution_info['stdout'] = stdout
                execution_info['stderr'] = stderr
                execution_info['return_code'] = process.returncode
                
            except subprocess.TimeoutExpired:
                process.kill()
                stdout, stderr = process.communicate()
                execution_info['stdout'] = stdout
                execution_info['stderr'] = stderr + "\n[Process terminated due to timeout]"
                execution_info['return_code'] = -1
            
            execution_info['duration'] = time.time() - start_time
            self.logger.info(f"Execution completed in {execution_info['duration']:.2f}s")
            
        except Exception as e:
            execution_info['stderr'] = str(e)
            execution_info['return_code'] = -1
            self.logger.error(f"Execution failed: {e}")
        
        return execution_info
    
    def post_execution_analysis(self) -> Dict[str, Any]:
        """Analyze system state after execution"""
        self.logger.info("Performing post-execution analysis")
        
        analysis = {
            'surviving_processes': self.get_surviving_processes(),
            'network_connections': self.monitoring_data['network_connections'],
            'file_system_changes': self.check_file_system_changes(),
            'memory_analysis': self.analyze_memory(),
            'iocs_extracted': self.extract_iocs()
        }
        
        return analysis
    
    def get_surviving_processes(self) -> List[Dict[str, Any]]:
        """Get processes still running after sample execution"""
        surviving = []
        for process_info in self.monitoring_data['processes']:
            try:
                pid = process_info['pid']
                if psutil.pid_exists(pid):
                    process = psutil.Process(pid)
                    surviving.append({
                        'pid': pid,
                        'name': process.name(),
                        'status': process.status(),
                        'memory_percent': process.memory_percent(),
                        'cpu_percent': process.cpu_percent()
                    })
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
        
        return surviving
    
    def check_file_system_changes(self) -> Dict[str, Any]:
        """Check for file system modifications"""
        changes = {
            'files_created': [],
            'files_modified': [],
            'files_deleted': []
        }
        
        # This would be implemented with proper file system monitoring
        # For now, return simulated data
        try:
            for root, dirs, files in os.walk(self.temp_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    changes['files_created'].append(file_path)
        except Exception as e:
            self.logger.error(f"File system check failed: {e}")
        
        return changes
    
    def analyze_memory(self) -> Dict[str, Any]:
        """Analyze memory for suspicious patterns"""
        # This would involve memory dumping and analysis
        # For basic sandbox, return simulated analysis
        return {
            'suspicious_patterns': ['MZ header in memory', 'Shellcode patterns'],
            'injected_processes': [],
            'memory_regions': []
        }
    
    def extract_iocs(self) -> Dict[str, Any]:
        """Extract Indicators of Compromise"""
        iocs = {
            'network_iocs': [],
            'file_iocs': [],
            'behavioral_iocs': [],
            'yara_rules': []
        }
        
        # Extract network IOCs from monitoring data
        for conn in self.monitoring_data['network_connections']:
            if conn['remote_address'] and conn['remote_address'] != 'None':
                iocs['network_iocs'].append({
                    'type': 'IP Address',
                    'value': conn['remote_address'],
                    'context': f"Connection from PID {conn['pid']}"
                })
        
        # Behavioral IOCs
        if len(self.monitoring_data['processes']) > 10:
            iocs['behavioral_iocs'].append('High process creation rate')
        
        if any('cmd.exe' in str(p.get('cmdline', [])) for p in self.monitoring_data['processes']):
            iocs['behavioral_iocs'].append('Command interpreter usage')
        
        return iocs
    
    def generate_report(self) -> Dict[str, Any]:
        """Generate comprehensive analysis report"""
        report = {
            'analysis_id': self.analysis_id,
            'sample_info': self.analysis_results['pre_analysis'],
            'execution_results': self.analysis_results['execution'],
            'behavioral_analysis': self.analysis_results['post_analysis'],
            'monitoring_data': self.monitoring_data,
            'verdict': self.generate_verdict(),
            'timestamp': datetime.now().isoformat(),
            'sandbox_version': '1.0'
        }
        
        return report
    
    def generate_verdict(self) -> Dict[str, Any]:
        """Generate malware verdict based on analysis"""
        score = 0
        reasons = []
        
        # Score based on various factors
        if len(self.analysis_results['pre_analysis']['suspicious_strings']['urls']) > 0:
            score += 20
            reasons.append("Suspicious URLs found in binary")
        
        if len(self.analysis_results['pre_analysis']['suspicious_strings']['ips']) > 0:
            score += 15
            reasons.append("Suspicious IP addresses found")
        
        if len(self.monitoring_data['network_connections']) > 5:
            score += 25
            reasons.append("High network activity")
        
        if len(self.monitoring_data['processes']) > 8:
            score += 20
            reasons.append("High process creation rate")
        
        if any('cmd' in p.get('name', '').lower() for p in self.monitoring_data['processes']):
            score += 10
            reasons.append("Command interpreter usage")
        
        # Determine verdict
        if score >= 70:
            verdict = "Malicious"
            confidence = "High"
        elif score >= 40:
            verdict = "Suspicious"
            confidence = "Medium"
        else:
            verdict = "Clean"
            confidence = "Low"
        
        return {
            'verdict': verdict,
            'confidence': confidence,
            'score': score,
            'reasons': reasons
        }
    
    def cleanup(self):
        """Clean up temporary files and processes"""
        self.logger.info("Cleaning up sandbox environment")
        
        # Kill any remaining processes spawned during analysis
        for process_info in self.monitoring_data['processes']:
            try:
                pid = process_info['pid']
                if psutil.pid_exists(pid):
                    process = psutil.Process(pid)
                    process.kill()
            except:
                pass
        
        # Remove temporary directory
        try:
            import shutil
            shutil.rmtree(self.temp_dir)
            self.logger.info(f"Removed temporary directory: {self.temp_dir}")
        except Exception as e:
            self.logger.error(f"Cleanup failed: {e}")

def main():
    parser = argparse.ArgumentParser(description='Basic Malware Analysis Sandbox')
    parser.add_argument('sample', help='Path to malware sample')
    parser.add_argument('-t', '--timeout', type=int, default=60, 
                       help='Execution timeout in seconds (default: 60)')
    parser.add_argument('-o', '--output', help='Output report file')
    parser.add_argument('--no-cleanup', action='store_true', 
                       help='Keep temporary files after analysis')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.sample):
        print(f"Error: Sample file '{args.sample}' not found")
        sys.exit(1)
    
    sandbox = MalwareSandbox(args.sample, args.timeout)
    
    try:
        report = sandbox.analyze_sample()
        
        # Output report
        if args.output:
            with open(args.output, 'w') as f:
                json.dump(report, f, indent=2)
            print(f"Report saved to: {args.output}")
        else:
            print(json.dumps(report, indent=2))
        
        # Print verdict
        verdict = report['verdict']
        print(f"\n=== VERDICT ===")
        print(f"Result: {verdict['verdict']} (Confidence: {verdict['confidence']})")
        print(f"Score: {verdict['score']}/100")
        print("Reasons:")
        for reason in verdict['reasons']:
            print(f"  - {reason}")
    
    except Exception as e:
        print(f"Analysis failed: {e}")
    
    finally:
        if not args.no_cleanup:
            sandbox.cleanup()

if __name__ == "__main__":
    main()
